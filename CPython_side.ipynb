{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3d3cf0",
   "metadata": {},
   "source": [
    "Вводная часть и некоторые общие положения об интерпретаторах питона, информация по установке и настройке, отличиях CPython и PyPy3 изложены в ридми [репозитория](https://github.com/Asklepiad/PyPy_vs_CPython.git) . В ноутбуках будут показаны тесты на конкретных примерах, демонстрирующие отличия в логике и производительности двух интерпретаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a745485",
   "metadata": {},
   "source": [
    "# 1. Скорость базового питона"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340155b0",
   "metadata": {},
   "source": [
    "## 1.1 Теоретическая посылка и базовый пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6163885",
   "metadata": {},
   "source": [
    "Считается, что PyPy значительно ускоряет базовый питон. Проверим, даст ли он индульгиенцию на использование двойных циклов. Сравним ресурсоемкий примтивный код на питоне и в PyPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8848ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 0 ns, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bad_naming = range(1000)\n",
    "for i in bad_naming:\n",
    "    for j in bad_naming:\n",
    "        for k in bad_naming:\n",
    "            i + j * k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce2904",
   "metadata": {},
   "source": [
    "Тройной цикл исполнялся `1 минуту, 21 секунду`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771d40a",
   "metadata": {},
   "source": [
    "## 1.2 Осмысленный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c603a",
   "metadata": {},
   "source": [
    "Попробуем что-нибудь более осмысленное, чем тройной цикл. Например, двойной цикл. Я взял свой код алгоритма Нидлмана-Вунша из первого семестра (опустим сейчас кривость и неоптимальность и посмотрим, как интепретаторы прожуют сие). Для сравнения я взял довольно длинные последовательности: по 10000 нуклеотидов каждый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d1788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a081103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.5 s, sys: 908 ms, total: 48.4 s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x, y = ''.join(random.choices(\"AGCT\", k=10000)), ''.join(random.choices(\"AGCT\", k=10000))\n",
    "n = len(x)\n",
    "m = len(y)\n",
    "mat = [[0 for j in range(m+1)] for i in range(n+1)]\n",
    "for j in range(m+1):\n",
    "    mat[0][j] = -j\n",
    "for i in range(n+1):\n",
    "    mat[i][0] = -i\n",
    "\n",
    "for i in range(1, n+1):\n",
    "    for j in range(1, m+1):\n",
    "        if x[i-1] == y[j-1]:\n",
    "            diag = mat[i-1][j-1]+1\n",
    "        else:\n",
    "            diag = mat[i-1][j-1]-1\n",
    "        mat[i][j] = max(diag, mat[i-1][j]-1, mat[i][j-1]-1)\n",
    "a1=[]\n",
    "a2=[]        \n",
    "\n",
    "while n>0 or m>0: \n",
    "    vert = mat[n-1][m]-1\n",
    "    hor = mat[n][m-1]-1  \n",
    "    if x[n-1] == y[m-1]:\n",
    "        diag1 = mat[n-1][m-1]+1\n",
    "    else:\n",
    "        diag1 = mat[n-1][m-1]-1\n",
    "    if mat[n][m] == vert:\n",
    "        a1.append(x[n-1])\n",
    "        a2.append(\"_\")\n",
    "        n -= 1\n",
    "    elif mat[n][m] == hor:\n",
    "        a1.append(\"_\")\n",
    "        a2.append(y[m-1])\n",
    "        m -= 1\n",
    "    elif mat[n][m] == diag1:\n",
    "        a1.append(x[n-1])\n",
    "        a2.append(y[m-1])\n",
    "        n -= 1\n",
    "        m -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490e6fe",
   "metadata": {},
   "source": [
    "Процесс отработал за `48.5 секунд`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1afd8",
   "metadata": {},
   "source": [
    "# 2. \"Стандартные биоинформатические\" библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e6470",
   "metadata": {},
   "source": [
    "## 2.1 Теоретическая посылка и загрузка пакетов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ce880",
   "metadata": {},
   "source": [
    "Считается, что со многими библиотеками (особенно написанными на Си для повышения производительности) PyPy работает крайне неоптимально. Это приводит к проигрышу в скорости по сравнению со стандартным интерпретатором питона. Проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad5b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ca0a4",
   "metadata": {},
   "source": [
    "## 2.2 Осмысленный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6df65d",
   "metadata": {},
   "source": [
    "Здесь используется один из скрпитов [семестрового проекта](https://github.com/Asklepiad/BI_project_2022.git). Этот скрипт осуществляет некоторые пертурбации с табличными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807d7f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the paralogs = 2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 12356/12356 [00:00<00:00, 85269.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 12356/12356 [00:08<00:00, 1538.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 288 ms, total: 11.1 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_path = \"/home/asklepiad/bioinf/start_codons/BI_project_2022\"\n",
    "folder_name = \"V_campbellii\"\n",
    "\n",
    "### Orto rows with singletons, but without paralog-containing rows\n",
    "\n",
    "# Uploading and modificating orto rows tables\n",
    "orto_rows = pd.read_csv(f\"{source_path}/{folder_name}/data/{folder_name}.proteinortho.tsv\", sep=\"\\t\") # Uploading dataframe with orto rows\n",
    "orto_rows = orto_rows.rename(columns = {\"# Species\": \"Species\"})\n",
    "orto_rows[\"ortologus_row\"] = orto_rows.index + 1 # Creating ortorows numbers\n",
    "\n",
    "# Uploading first csv-table and creating a new column in it\n",
    "orto_rows_list = orto_rows.index\n",
    "df1 = pd.read_csv(f\"{source_path}/{folder_name}/data/First_table.csv\")\n",
    "\n",
    "#Filling orto_row column (sounds like an oxymoron)\n",
    "assemblies = orto_rows.columns[3:-1]\n",
    "row_assigner = pd.melt(orto_rows, id_vars=[\"ortologus_row\"], value_vars=assemblies)\n",
    "row_assigner = row_assigner.query(\"value != '*'\")\n",
    "row_assigner[\"value\"] = row_assigner[\"value\"].str[:14]\n",
    "row_assigner\n",
    "row_assigner.drop([\"variable\"], axis=\"columns\", inplace=True)\n",
    "row_assigner.columns = [\"ortologus_row\", \"id\"]\n",
    "df1 = df1.merge(row_assigner, on=\"id\")\n",
    "\n",
    "# Number of the paralogs\n",
    "print(\"Number of the paralogs =\", sum(orto_rows.query(\"Genes > Species\").Genes) - sum(orto_rows.query(\"Genes > Species\").Species))\n",
    "\n",
    "# Creating a subset without pararows\n",
    "pararows_numbers = orto_rows.query(\"Genes > Species\").ortologus_row\n",
    "df1 = df1.query(\"ortologus_row not in @pararows_numbers\").query(\"ortologus_row != 0\")\n",
    "\n",
    "# Compiling data about start-codons of ortologus rows\n",
    "start_codon_per_row = df1.groupby(\"ortologus_row\", as_index=False).agg({\"start_codone\": \".\".join})\n",
    "start_codon_per_row[\"start_codone\"]\n",
    "orr_start_list = []\n",
    "for number in tqdm(range(len(start_codon_per_row))):\n",
    "    orr_start_list.append(start_codon_per_row.iloc[number, 1].split(\".\"))\n",
    "start_codons = pd.DataFrame(\n",
    "    {\n",
    "        \"ortologus_row\": start_codon_per_row[\"ortologus_row\"],\n",
    "        \"start_codons\": pd.Series(orr_start_list),\n",
    "        \"ATG\": 0.0,\n",
    "        \"GTG\": 0.0,\n",
    "        \"TTG\": 0.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Computing frequencies of exact start-codons\n",
    "start_codons.sort_values(\"ortologus_row\", inplace=True)\n",
    "for row in tqdm(range(len(start_codons))):\n",
    "    freqs = pd.Series(start_codons[\"start_codons\"][row]).value_counts() # If it will be need to visualize percents, use normalize=True in brackets\n",
    "    rowlength = len(start_codons[\"start_codons\"][row])\n",
    "    if \"ATG\" in freqs:\n",
    "        start_codons[\"ATG\"][row] = freqs[\"ATG\"]\n",
    "    else:\n",
    "        start_codons[\"ATG\"][row] = 0\n",
    "    if \"GTG\" in freqs:\n",
    "        start_codons[\"GTG\"][row] = freqs[\"GTG\"]\n",
    "    else:\n",
    "        start_codons[\"GTG\"][row] = 0\n",
    "    if \"TTG\" in freqs:\n",
    "        start_codons[\"TTG\"][row] = freqs[\"TTG\"]\n",
    "    else:\n",
    "        start_codons[\"TTG\"][row] = 0\n",
    "\n",
    "# Computing uniformity of start-codon per ortologus row\n",
    "start_codons[\"uniformity\"] = \"NA\"\n",
    "for row in range(len(start_codons)):\n",
    "    if len(set(start_codons.iloc[row, 1])) == 1:\n",
    "        start_codons.iloc[row, 5] = \"same\"\n",
    "    else:\n",
    "        start_codons.iloc[row, 5] = \"different\"\n",
    "\n",
    "# Constructing table withh all data about the ortologus rows (including pararows)\n",
    "start_codons2 = start_codons.merge(orto_rows, on=\"ortologus_row\", how=\"outer\")\n",
    "\n",
    "# Creating a table, combining data about gene and its start-codone\n",
    "strain_gene_row = start_codons2[[\"Species\", \"Genes\", \"ortologus_row\", \"uniformity\", \"ATG\", \"GTG\", \"TTG\"]]   # Other codons deleted\n",
    "summary_rows = df1.merge(strain_gene_row, on=\"ortologus_row\")\n",
    "\n",
    "# Assigning cog to orto_row\n",
    "row_cog = row_assigner.merge(df1[[\"id\", \"cog\"]], on=\"id\").groupby(\"ortologus_row\").agg({\"cog\": \"max\"})\n",
    "start_codons2 = start_codons2.merge(row_cog, on=\"ortologus_row\")\n",
    "\n",
    "# Adding organism_name to datasets\n",
    "summary_rows[\"organism\"] = folder_name\n",
    "start_codons2[\"organism\"] = folder_name\n",
    "\n",
    "uniq_cog = start_codons2[[\"ortologus_row\", \"ATG\", \"GTG\", \"TTG\", \"uniformity\", \"Species\", \"Genes\", \"cog\", \"organism\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e3158",
   "metadata": {},
   "source": [
    "Время исполнения - `11.2 секунды`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1dbbc",
   "metadata": {},
   "source": [
    "# 3. Потомки встроенных типов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e0d2a",
   "metadata": {},
   "source": [
    "## 3.1 Теоретический блок и базовый пример."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2825c86",
   "metadata": {},
   "source": [
    "В CPython и в PyPy по-разному реализовано поведение при добавлении атрибутов извне. CPython предпочитает ориентироваться запись атрибутов извне, а PyPy - на метод `__getitem__`.\n",
    "\n",
    "У меня нет мыслей, как это можно использовать. Пока ощущение только, что это нужно иметь в виду, дабы не попасться на различиях.\n",
    "\n",
    "Пример взят из [документации PyPy](https://doc.pypy.org/en/latest/cpython_differences.html#subclasses-of-built-in-types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3214d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython way\n"
     ]
    }
   ],
   "source": [
    "class D(dict):\n",
    "    def __getitem__(self, key):\n",
    "        if key == 'print':\n",
    "            return print\n",
    "        return \"PyPy way\"\n",
    "\n",
    "class A(object):\n",
    "    pass\n",
    "\n",
    "a = A()\n",
    "a.__dict__ = D()\n",
    "a.foo = \"CPython way\"\n",
    "print(a.foo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
